{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scanpy as sc\n",
    "\n",
    "input_dir = \"/work/magroup/skrieger/tissue_generator/quantized_slices/subclass_z1_d338_0_rotated\"\n",
    "\n",
    "sorted_slices = [\n",
    "    \"sec_05.h5ad\", \"sec_06.h5ad\", \"sec_08.h5ad\", \"sec_09.h5ad\", \"sec_10.h5ad\",\n",
    "    \"sec_11.h5ad\", \"sec_12.h5ad\", \"sec_13.h5ad\", \"sec_14.h5ad\", \"sec_15.h5ad\",\n",
    "    \"sec_16.h5ad\", \"sec_17.h5ad\", \"sec_18.h5ad\", \"sec_19.h5ad\", \"sec_24.h5ad\",\n",
    "    \"sec_25.h5ad\", \"sec_26.h5ad\", \"sec_27.h5ad\", \"sec_28.h5ad\", \"sec_29.h5ad\",\n",
    "    \"sec_30.h5ad\", \"sec_31.h5ad\", \"sec_32.h5ad\", \"sec_33.h5ad\", \"sec_35.h5ad\",\n",
    "    \"sec_36.h5ad\", \"sec_37.h5ad\", \"sec_38.h5ad\", \"sec_39.h5ad\", \"sec_40.h5ad\",\n",
    "    \"sec_42.h5ad\", \"sec_43.h5ad\", \"sec_44.h5ad\", \"sec_45.h5ad\", \"sec_46.h5ad\",\n",
    "    \"sec_47.h5ad\", \"sec_48.h5ad\", \"sec_49.h5ad\", \"sec_50.h5ad\", \"sec_51.h5ad\",\n",
    "    \"sec_52.h5ad\", \"sec_54.h5ad\", \"sec_55.h5ad\", \"sec_56.h5ad\", \"sec_57.h5ad\",\n",
    "    \"sec_58.h5ad\", \"sec_59.h5ad\", \"sec_60.h5ad\", \"sec_61.h5ad\", \"sec_62.h5ad\",\n",
    "    \"sec_64.h5ad\", \"sec_66.h5ad\", \"sec_67.h5ad\"\n",
    "]\n",
    "\n",
    "sorted_slices = [\"sec_30.h5ad\", \"sec_31.h5ad\", \"sec_32.h5ad\", \"sec_33.h5ad\", \"sec_35.h5ad\", \"sec_36.h5ad\", \"sec_37.h5ad\", \"sec_38.h5ad\", \"sec_39.h5ad\", \"sec_40.h5ad\"]\n",
    "# sorted_slices = [\"sec_30.h5ad\", \"sec_31.h5ad\", \"sec_32.h5ad\"]\n",
    "# sorted_slices = [\"sec_40.h5ad\"]\n",
    "# sorted_slices=[\"sec_38.h5ad\", \"sec_39.h5ad\", \"sec_40.h5ad\"]\n",
    "representations = [sc.read_h5ad(os.path.join(input_dir, fname)) for fname in sorted_slices]\n",
    "for rep in representations:\n",
    "    rep.obsm[\"spatial\"]=rep.obsm[\"original_spatial\"]\n",
    "\n",
    "slices=representations\n",
    "print(f\"Loaded {len(slices)} anndata objects into memory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(location)\n",
    "from alignment_model import AlignementModel\n",
    "\n",
    "density_model = AlignementModel(slices, z_posn=[-1, 0, 1], pin_key=\"parcellation_structure\", use_ccf=True)\n",
    "density_model.fit()\n",
    "aligned_slices = density_model.get_common_coordinate_locations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(gene_exp|token)\n",
    "from gene_exp_model import GeneExpModel\n",
    "# aligned_slices=aligned_slices[-5:-4]\n",
    "gene_exp_model = GeneExpModel(aligned_slices, use_subclass=True)\n",
    "gene_exp_model.fit()\n",
    "slices_tokenized = gene_exp_model.get_tokenized_slices()\n",
    "# test_slice=slices_tokenized[0]\n",
    "test_slice=slices_tokenized[-5]\n",
    "val_slice=slices_tokenized[-2]\n",
    "slices_tokenized=slices_tokenized[:-5]+slices_tokenized[-4:-2]+slices_tokenized[-1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(region|location)\n",
    "from celltype_model import CelltypeModel\n",
    "\n",
    "region_model = CelltypeModel(slices_tokenized,gene_exp_model.num_tokens, val_slice=val_slice, epochs=100,learning_rate=0.001, batch_size=32, device=\"cuda\")\n",
    "\n",
    "region_model.fit()\n",
    "# region_model.load_model(\"ops/distance_transform_temp/best_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import rc_context\n",
    "from metrics import *\n",
    "from analysis import *\n",
    "\n",
    "device=\"cuda\"\n",
    "xyz_samples = torch.tensor(test_slice.obsm[\"aligned_spatial\"], dtype=torch.float32).to(device)\n",
    "density_tensor = torch.tensor(test_slice.obs[\"entropy\"], dtype=torch.float32).to(device)\n",
    "xyz_samples= torch.cat([xyz_samples,density_tensor.unsqueeze(-1)],dim=-1)\n",
    "adata_argmax, _ = generate_anndata_from_samples(region_model, xyz_samples, device, sample_from_probs=False)\n",
    "adata_sampled, _ = generate_anndata_from_samples(region_model, xyz_samples, device, sample_from_probs=True)\n",
    "print(soft_accuracy(test_slice.obs[\"token\"].to_numpy().tolist(),test_slice.obsm[\"aligned_spatial\"],adata_sampled.obs[\"token\"].tolist(),adata_sampled.obsm[\"spatial\"],radius=0.05))\n",
    "\n",
    "assign_shared_colors([adata_argmax,adata_sampled,test_slice], color_key=\"token\")\n",
    "plot_spatial_with_palette(test_slice, color_key=\"token\", spot_size=0.001, figsize=(30,30))\n",
    "plot_spatial_with_palette(test_slice, color_key=\"entropy\", spot_size=0.002, figsize=(30,30))\n",
    "plot_spatial_with_palette(adata_argmax, color_key=\"token\", spot_size=0.001, figsize=(30,30))\n",
    "plot_spatial_with_palette(adata_sampled, color_key=\"token\", spot_size=0.001, figsize=(30,30))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env_4_26",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
